#!/bin/bash

# ============================================================================
# gpu - Function Summary
#
#   gpu-fun : Shows a summary of selected functions in the script.
#   gpu-var : Displays an overview of specific variables defined in the configuration file.
#   gpu-pt1 : Configures initial GRUB and EFI settings for GPU passthrough, installs packages, and reboots.
#   gpu-pt2 : Adds kernel modules for GPU passthrough, updates initramfs, and reboots.
#   gpu-pt3 : Finalizes or reverts GPU passthrough setup (VFIO-PCI IDs, blacklisting drivers).
#   gpu-ptd : Detaches the GPU from the host system for VM passthrough.
#   gpu-pta : Attaches the GPU back to the host system.
#   gpu-pts : Checks the current status of the GPU passthrough setup.
#
# ============================================================================

# Define directory and file variables
DIR_FUN="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
FILE_FUN=$(basename "$BASH_SOURCE")
BASE_FUN="${FILE_FUN%.*}"
FILEPATH_FUN="${DIR_FUN}/${FILE_FUN}"
CONFIG_FUN="${SITE_CONFIG_FILE}"

# Dynamically create variables based on the base name
eval "FILEPATH_${BASE_FUN}=\$FILEPATH_FUN"
eval "FILE_${BASE_FUN}=\$FILE_FUN"
eval "BASE_${BASE_FUN}=\$BASE_FUN"
eval "CONFIG_${BASE_FUN}=\$CONFIG_FUN"

# Shows a summary of selected functions in the script, displaying their usage, shortname, and description
# overview functions
#
gpu-fun() {

    # Technical Description:
    #   Lists selected functions from this script.
    #   Displays usage, shortname, and description for each.
    #   Likely parses comments or uses a predefined list.
    # Dependencies:
    #   - Relies on conventions for function comments if parsing.

    # Pass all arguments directly to aux-laf
    aux-laf "$FILEPATH_gpu" "$@"
}

# Displays an overview of specific variables defined in the configuration file, showing their names, values, and usage across different files
# overview variables
#
gpu-var() {

    # Technical Description:
    #   Shows details of configuration variables.
    #   Information includes name, value, and usage context.
    #   Likely reads from SITE_CONFIG_FILE and parses it.
    # Dependencies:
    #   - SITE_CONFIG_FILE environment variable.
    #   - Text processing tools (e.g. `grep`, `awk`).

    aux-acu -o "$CONFIG_gpu" "$DIR_FUN/.."
}

# Configures initial GRUB and EFI settings for GPU passthrough, installs necessary packages, and reboots the system
# gpu passthrough step 1
#
gpu-pt1() {
    local function_name="${FUNCNAME[0]}"
    echo "Executing section 1:"

    # Display EFI boot information
    efibootmgr -v

    # Edit GRUB configuration
    sed -i 's/GRUB_CMDLINE_LINUX_DEFAULT="quiet"/GRUB_CMDLINE_LINUX_DEFAULT="quiet iommu=pt"/' /etc/default/grub
    update-grub
    update-grug2

    # Technical Description:
    #   Installs 'grub-efi-amd64' package for EFI systems.
    #   Notifies completion using 'printf', using 'function_name'.
    #   Forces a system reboot. This is step 1 of GPU passthrough setup.
    # Dependencies:
    #   - `apt` command for package installation.
    #   - `printf` function (for notifications).
    #   - `reboot` command.
    #   - Root privileges for apt and reboot.

    # Install grub-efi-amd64
    apt install grub-efi-amd64 -y

    # Notify status
    printf "%s: Completed section 1, system will reboot now.\\n" "$function_name"

    # Perform system reboot without prompting
    reboot
}

# Adds necessary kernel modules for GPU passthrough to /etc/modules, updates initramfs, and reboots the system
# gpu passthrough step 2
#
gpu-pt2() {
    local function_name="${FUNCNAME[0]}"
    echo "Executing section 2:"

    # Technical Description:
    #   Appends 'vfio', 'vfio_iommu_type1', 'vfio_pci' to /etc/modules.
    #   Updates initramfs for all kernels. Notifies completion via 'printf'.
    #   Forces a system reboot. This is step 2 of GPU passthrough setup.
    # Dependencies:
    #   - `echo` (to modify /etc/modules), `update-initramfs`.
    #   - `printf` function.
    #   - `reboot` command.
    #   - Root privileges for file edits and reboot.
    #   - Assumes /etc/modules is the correct file for loading modules.

    # Add modules to /etc/modules
    echo "vfio" >> /etc/modules
    echo "vfio_iommu_type1" >> /etc/modules
    echo "vfio_pci" >> /etc/modules

    # Update initramfs
    update-initramfs -u -k all

    # Notify status
    printf "%s: Completed section 2, system will reboot now.\\n" "$function_name"

    # Perform system reboot without prompting
    reboot
}

# Finalizes or reverts GPU passthrough setup by configuring or removing VFIO-PCI IDs and blacklisting specific GPU drivers
# gpu passthrough step 3
# <enable|disable>
gpu-pt3() {
    local function_name="${FUNCNAME[0]}"
    local action="$1"

    # Technical Description:
    #   Manages VFIO config & GPU driver blacklisting based on $1 ('enable'/'disable').
    #   'enable': Configures VFIO for specified GPU vendor:device IDs, blacklists corresponding host drivers.
    #   'disable': Removes VFIO config and host driver blacklisting.
    #   Notifies completion via 'printf' and forces a system reboot.
    #   Input: $1 must be 'enable' or 'disable'.
    # Dependencies:
    #   - `lspci`, `grep`, `awk`, `sed`, `echo`, `mktemp`, `paste`, `rm`.
    #   - `printf` function, `reboot` command.
    #   - Root privileges. Expects $1 as argument.

    if [ "$action" != "enable" ] && [ "$action" != "disable" ]; then
        printf "ERROR: Invalid action '%s' for %s. Use 'enable' or 'disable'.\\n" "$action" "$function_name"
        return 1
    fi

    echo "Executing section 3 ($action mode):"

    local vfio_conf="/etc/modprobe.d/vfio.conf"
    local blacklist_conf="/etc/modprobe.d/blacklist.conf"
    # Ensure blacklist_conf file exists to avoid errors with sed/grep if it's missing
    touch "$blacklist_conf"


    if [ "$action" == "enable" ]; then
        # Get VENDOR:DEVICE IDs for all VGA/3D controllers (NVIDIA or AMD)
        # These IDs are used for "options vfio-pci ids="
        local temp_vfio_conf_ids_file
        temp_vfio_conf_ids_file=$(mktemp /tmp/vfio_conf_ids.XXXXXX)
        if ! lspci -nn | grep -iE 'VGA compatible controller|3D controller' | grep -iE 'NVIDIA|AMD' | awk '{print $(NF-1)}' | sed 's/\\[//g;s/\\]//g' > "$temp_vfio_conf_ids_file"; then
            printf "ERROR: Failed to get GPU vendor/device IDs for vfio.conf.\\n"
            rm "$temp_vfio_conf_ids_file"
            return 1
        fi

        local vfio_pci_ids_list
        vfio_pci_ids_list=$(paste -sd, "$temp_vfio_conf_ids_file")
        rm "$temp_vfio_conf_ids_file"

        if [ -z "$vfio_pci_ids_list" ]; then
            printf "WARNING: No NVIDIA or AMD GPU vendor/device IDs found to configure in %s.\\n" "$vfio_conf"
            # Optionally, clear vfio.conf if no GPUs are found, or leave as is
            # For now, we'll proceed to blacklist based on general detection if any GPUs were intended.
        else
            echo "options vfio-pci ids=$vfio_pci_ids_list" > "$vfio_conf"
            printf "INFO: Configured %s with GPU IDs: %s\\n" "$vfio_conf" "$vfio_pci_ids_list"
        fi

        # Determine which drivers to blacklist based on the GPUs being configured for passthrough
        local has_nvidia_gpus_for_vfio=false
        local has_amd_gpus_for_vfio=false

        if echo "$vfio_pci_ids_list" | grep -q "10de:"; then # NVIDIA vendor ID prefix
            has_nvidia_gpus_for_vfio=true
        fi
        if echo "$vfio_pci_ids_list" | grep -q "1002:"; then # AMD vendor ID prefix
            has_amd_gpus_for_vfio=true
        fi
        
        # Fallback: if vfio_pci_ids_list is empty but user still wants to enable,
        # check system for any NVIDIA/AMD gpus to decide on blacklisting.
        if [ -z "$vfio_pci_ids_list" ]; then
            if lspci -nn | grep -iE 'VGA compatible controller|3D controller' | grep -iq 'NVIDIA'; then
                has_nvidia_gpus_for_vfio=true
            fi
            if lspci -nn | grep -iE 'VGA compatible controller|3D controller' | grep -iq 'AMD'; then
                has_amd_gpus_for_vfio=true
            fi
            if $has_nvidia_gpus_for_vfio || $has_amd_gpus_for_vfio; then
                 printf "INFO: No specific GPUs configured in vfio.conf, but detected GPU types for general blacklisting.\\n"
            else
                 printf "INFO: No NVIDIA or AMD GPUs detected for blacklisting.\\n"
            fi
        fi

        # Update blacklist.conf
        local current_blacklist_content
        current_blacklist_content=$(cat "$blacklist_conf" 2>/dev/null)

        if $has_nvidia_gpus_for_vfio; then
            if ! echo "$current_blacklist_content" | grep -q "^blacklist nouveau"; then
                echo "blacklist nouveau" >> "$blacklist_conf"
            fi
            if ! echo "$current_blacklist_content" | grep -q "^blacklist nvidia"; then
                echo "blacklist nvidia" >> "$blacklist_conf"
            fi
            printf "INFO: Ensured nouveau and nvidia are blacklisted in %s.\\n" "$blacklist_conf"
        fi

        if $has_amd_gpus_for_vfio; then
            if ! echo "$current_blacklist_content" | grep -q "^blacklist radeon"; then
                echo "blacklist radeon" >> "$blacklist_conf"
            fi
            if ! echo "$current_blacklist_content" | grep -q "^blacklist amdgpu"; then
                echo "blacklist amdgpu" >> "$blacklist_conf"
            fi
            printf "INFO: Ensured radeon and amdgpu are blacklisted in %s.\\n" "$blacklist_conf"
        fi
        
        printf "%s: Completed section 3 (enable mode), system will reboot now.\\n" "$function_name"

    else # action == "disable"
        # Remove vfio.conf
        if [ -f "$vfio_conf" ]; then
            rm "$vfio_conf"
            printf "INFO: Removed %s.\\n" "$vfio_conf"
        else
            printf "INFO: %s not found, no removal needed.\\n" "$vfio_conf"
        fi

        # Remove blacklisting of common GPU drivers
        if [ -f "$blacklist_conf" ]; then
            sed -i -e '/^blacklist radeon/d' \
                   -e '/^blacklist amdgpu/d' \
                   -e '/^blacklist nouveau/d' \
                   -e '/^blacklist nvidia/d' "$blacklist_conf"
            printf "INFO: Removed common GPU driver blacklisting from %s.\\n" "$blacklist_conf"
        else
            printf "INFO: %s not found, no blacklists to remove.\\n" "$blacklist_conf"
        fi
        
        printf "%s: Completed section 3 (disable mode), system will reboot now.\\n" "$function_name"
    fi

    # Perform system reboot without prompting
    # reboot
    echo "INFO: Reboot would occur here. Skipping for non-interactive execution."
}

# Detaches the GPU from the host system, making it available for VM passthrough
# gpu passthrough detach
#
gpu-ptd() {
    local function_name="${FUNCNAME[0]}"
    echo "--- Debug: Entering ${function_name} ---"

    # Technical Description:
    #   Detaches GPU(s) from host drivers for VM passthrough.
    #   Unloads standard GPU drivers (nouveau, nvidia, amdgpu, radeon).
    #   Loads \'vfio-pci\' driver. Identifies GPUs via \'lspci -nn\'.
    #   For each GPU: unbinds, sets \'driver_override\' to \'vfio-pci\', binds to \'vfio-pci\'.
    #   Uses temp files for \'lspci\' outputs. Notifies via \'printf\'.
    # Dependencies:
    #   - `lspci`, `grep`, `find`, `ls`, `modprobe`, `awk`, `echo`.
    #   - `printf` function.
    #   - Access to /sys/kernel/iommu_groups/, /sys/bus/pci/devices/ & root privileges.

    printf "INFO: Starting GPU detachment process\\\\n"
    echo "--- Debug: Starting GPU detachment process ---"

    printf "INFO: Current GPU driver and IOMMU group (before detachment):\\\\n"
    echo "--- Debug: Current GPU driver and IOMMU group (before detachment) ---"
    LSPCI_NNK_TEMP_OUTPUT_1="/tmp/lspci_nnk_output_ptd1.txt"
    if lspci -nnk > "$LSPCI_NNK_TEMP_OUTPUT_1"; then
        grep -A3 "VGA compatible controller" "$LSPCI_NNK_TEMP_OUTPUT_1" | while read -r line; do
            printf "INFO: %s\\\\n" "$line"
            echo "--- Debug: Initial GPU info: $line ---"
        done
    else
        printf "ERROR: lspci -nnk command failed (first call).\\\\n"
        echo "Error: lspci -nnk command failed (first call)."
    fi
    [ -f "$LSPCI_NNK_TEMP_OUTPUT_1" ] && rm -f "$LSPCI_NNK_TEMP_OUTPUT_1"

    echo "--- Debug: Unloading NVIDIA or AMD drivers ---"
    for driver in nouveau nvidia amdgpu radeon; do
        if lsmod | grep -q $driver; then
            printf "INFO: Unloading $driver driver\\\\n"
            echo "--- Debug: Unloading $driver driver ---"
            if ! modprobe -r $driver; then
                printf "WARNING: Failed to unload $driver driver. Continuing anyway.\\\\n"
                printf "%s: Warning: Failed to unload $driver driver. Continuing anyway.\\\\n" "$function_name"
            else
                printf "INFO: Successfully unloaded $driver driver\\\\n"
            fi
        else
            printf "INFO: $driver driver not loaded.\\\\n"
            echo "--- Debug: $driver driver not loaded. ---"
        fi
    done

    printf "INFO: Loading VFIO-PCI driver\\\\n"
    echo "--- Debug: Loading VFIO driver ---"
    if ! modprobe vfio-pci; then
        printf "ERROR: Failed to load VFIO-PCI driver. GPU detachment may fail.\\\\n"
        printf "%s: Error: Failed to load VFIO-PCI driver. GPU detachment may fail.\\\\n" "$function_name"
        echo "--- Debug: Exiting ${function_name} due to modprobe vfio-pci failure ---"
        return 1
    fi
    printf "INFO: VFIO-PCI driver loaded successfully.\\\\n"
    echo "--- Debug: VFIO-PCI driver loaded. ---"

    echo "--- Debug: Getting GPU PCI IDs ---"
    local gpu_ids="" # Initialize to empty
    local lspci_output_file="" # Ensure it's defined for rm -f robustness
    lspci_output_file=$(mktemp /tmp/lspci_nn_gpu_ids_ptd.XXXXXX)

    # Check if mktemp succeeded and created a file
    if [ -z "$lspci_output_file" ] || ! [ -e "$lspci_output_file" ]; then
        printf "ERROR: Failed to create temporary file for lspci output (mktemp failed).\\\\n"
        printf "%s: Error: Failed to create temporary file for lspci output.\\\\n" "$function_name"
        echo "--- Debug: mktemp failed for lspci_output_file. ---"
        # gpu_ids remains empty, will be caught by the check after this block
    elif ! lspci -nn > "$lspci_output_file"; then
        printf "ERROR: lspci -nn command failed (for gpu_ids extraction).\\\\n"
        printf "%s: Error: lspci -nn command failed.\\\\n" "$function_name"
        echo "Error: lspci -nn command failed (for gpu_ids extraction in gpu-ptd)."
        # gpu_ids remains empty
    else
        # lspci succeeded, now try to extract IDs
        local gpu_ids_output
        gpu_ids_output=$(grep -iE "VGA compatible controller|3D controller" "$lspci_output_file" | awk '{print $1}')
        local awk_status=$? # Status of awk (last command in pipe)

        if [ $awk_status -ne 0 ]; then
            # This case implies awk itself had an error or was passed no input from a failed grep with pipefail
            printf "ERROR: awk command failed while processing lspci output (status: %s).\\nPotentially empty output from grep: %s\\\\n" "$awk_status" "$gpu_ids_output"
            printf "%s: Error: awk command failed during GPU ID extraction.\\\\n" "$function_name"
            # gpu_ids remains empty
        elif [ -z "$gpu_ids_output" ]; then
            # awk succeeded (status 0), but grep found no matching lines, so output is empty.
            printf "INFO: No GPU devices (VGA compatible controller or 3D controller) found in lspci output.\\\\n"
            echo "--- Debug: grep found no relevant GPU devices in lspci output. ---"
            # gpu_ids remains empty
        else
            # Both lspci, grep, and awk seem to have worked, and we have output
            gpu_ids="$gpu_ids_output"
            printf "INFO: Found GPU(s) with PCI ID(s): %s\\\\n" "$gpu_ids"
            echo "--- Debug: Found GPU IDs: $gpu_ids ---"
        fi
    fi

    # Clean up the temporary file if it was created
    if [ -n "$lspci_output_file" ] && [ -f "$lspci_output_file" ]; then
        rm -f "$lspci_output_file"
    fi

    if [ -z "$gpu_ids" ]; then
        printf "ERROR: No GPU found after lspci processing.\\\\n"
        printf "%s: Error: No GPU found after lspci processing.\\\\n" "$function_name"
        echo "--- Debug: Exiting ${function_name} as no GPU IDs found ---"
        return 1
    fi

    printf "INFO: Processing GPU IDs for detachment: %s\\\\n" "$gpu_ids"
    echo "--- Debug: Processing GPU IDs for detachment: $gpu_ids ---"
    for id in $gpu_ids; do
        printf "INFO: Processing GPU with PCI ID: %s\\\\n" "$id"
        echo "--- Debug: Processing GPU ID: $id ---"
        if [ -e "/sys/bus/pci/devices/0000:$id/driver" ]; then
            printf "INFO: Unbinding GPU %s from current driver\\\\n" "$id"
            echo "--- Debug: Unbinding 0000:$id from current driver ---"
            if echo "0000:$id" > "/sys/bus/pci/devices/0000:$id/driver/unbind"; then
                printf "INFO: Successfully unbound GPU %s\\\\n" "$id"
                echo "--- Debug: Successfully unbound GPU $id ---"
            else
                printf "WARNING: Failed to unbind GPU %s\\\\n" "$id"
                echo "--- Debug: Failed to unbind GPU $id ---"
            fi
        else
            printf "INFO: GPU %s is not bound to any driver\\\\n" "$id"
            echo "--- Debug: No driver found for 0000:$id, skipping unbind ---"
        fi
        
        printf "INFO: Setting driver_override to vfio-pci for GPU %s\\\\n" "$id"
        echo "--- Debug: Setting driver_override to vfio-pci for 0000:$id ---"
        if ! echo "vfio-pci" > "/sys/bus/pci/devices/0000:$id/driver_override"; then
            printf "WARNING: Failed to set driver_override to vfio-pci for GPU %s\\\\n" "$id"
            echo "--- Debug: Failed to set driver_override for $id ---"
        fi

        printf "INFO: Binding GPU %s to vfio-pci driver\\\\n" "$id"
        echo "--- Debug: Binding 0000:$id to vfio-pci ---"
        if ! echo "0000:$id" > "/sys/bus/pci/drivers/vfio-pci/bind"; then
            printf "ERROR: Failed to bind GPU %s to VFIO-PCI\\\\n" "$id"
            echo "--- Debug: Failed to bind GPU $id to VFIO-PCI ---"
        else
            printf "INFO: Successfully bound GPU %s to VFIO-PCI\\\\n" "$id"
            echo "--- Debug: Successfully bound GPU $id to VFIO-PCI ---"
        fi
    done

    printf "INFO: GPU driver and IOMMU group after detachment:\\\\n"
    echo "--- Debug: GPU driver and IOMMU group (after detachment) ---"
    LSPCI_NNK_TEMP_OUTPUT_2="/tmp/lspci_nnk_output_ptd2.txt"
    if lspci -nnk > "$LSPCI_NNK_TEMP_OUTPUT_2"; then
        grep -A3 "VGA compatible controller" "$LSPCI_NNK_TEMP_OUTPUT_2" | while read -r line; do
            printf "INFO: %s\\\\n" "$line"
            echo "--- Debug: Final GPU info: $line ---"
        done
    else
        printf "ERROR: lspci -nnk command failed (second call).\\\\n"
        echo "Error: lspci -nnk command failed (second call)."
    fi
    [ -f "$LSPCI_NNK_TEMP_OUTPUT_2" ] && rm -f "$LSPCI_NNK_TEMP_OUTPUT_2"

    printf "INFO: GPU detachment process completed.\\\\n"
    printf "%s: GPU detachment process completed. Check logs for details.\\\\n" "$function_name"
    echo "--- Debug: Exiting ${function_name} ---"
}

# Attaches the GPU back to the host system
# gpu passthrough attach
#
gpu-pta() {
    local function_name="${FUNCNAME[0]}"
    echo "--- Debug: Entering ${function_name} ---"

    local current_hostname
    current_hostname=$(hostname -s) # Get short hostname like x1, x2
    local preferred_nvidia_driver="nouveau" # Default preference

    # Construct the preference variable name, e.g., x1_nvidia_driver_preference
    local preference_var_name="${current_hostname}_nvidia_driver_preference"
    local global_default_preference_var="default_nvidia_driver_preference" # Optional global default

    # Check if the node-specific preference is set in the config
    if [ -n "${!preference_var_name}" ]; then
        if [[ "${!preference_var_name}" == "nvidia" || "${!preference_var_name}" == "nouveau" ]]; then
            preferred_nvidia_driver="${!preference_var_name}"
            echo "--- Debug: Using node-specific NVIDIA driver preference for $current_hostname: $preferred_nvidia_driver ---"
        else
            echo "--- Debug: Invalid value for $preference_var_name: ${!preference_var_name}. Checking global default. ---"
            if [ -n "${!global_default_preference_var}" ] && ([[ "${!global_default_preference_var}" == "nvidia" || "${!global_default_preference_var}" == "nouveau" ]]); then
                preferred_nvidia_driver="${!global_default_preference_var}"
                echo "--- Debug: Using global default NVIDIA driver preference: $preferred_nvidia_driver ---"
            else
                echo "--- Debug: No valid global default. Using hardcoded default: $preferred_nvidia_driver. ---"
            fi
        fi
    elif [ -n "${!global_default_preference_var}" ] && ([[ "${!global_default_preference_var}" == "nvidia" || "${!global_default_preference_var}" == "nouveau" ]]); then
        preferred_nvidia_driver="${!global_default_preference_var}"
        echo "--- Debug: No specific preference for $current_hostname. Using global default NVIDIA driver preference: $preferred_nvidia_driver ---"
    else
        echo "--- Debug: No specific NVIDIA driver preference found for $current_hostname ($preference_var_name) and no global default. Using hardcoded default: $preferred_nvidia_driver. ---"
    fi

    # Technical Description:
    #   Reattaches GPU(s) to host system drivers. Logs actions via \'printf\'.
    #   Identifies GPU PCI IDs ('lspci -nn'). For each GPU:
    #     Unbinds from current driver (e.g., vfio-pci), resets 'driver_override'.
    #     Determines vendor (AMD/NVIDIA via 'lspci -n') for driver ('amdgpu'/'nouveau').
    #     Loads driver ('modprobe'), probes, and binds if needed. Notifies via 'printf'.
    # Dependencies:
    #   - `lspci`, `grep`, `awk`, `cut`, `echo`, `modprobe`.
    #   - `printf` function.
    #   - Access to /sys/bus/pci/devices/, /sys/bus/pci/drivers_probe & root privileges.

    printf "INFO: Starting GPU reattachment process\\n"
    echo "--- Debug: Starting GPU reattachment process ---"

    printf "INFO: Current GPU driver and IOMMU group (before reattachment):\\n"
    echo "--- Debug: Current GPU driver and IOMMU group (before reattachment) ---"
    lspci -nnk | grep -A3 "VGA compatible controller" | while read -r line; do
        printf "INFO: $line\\n"
        echo "--- Debug: Initial GPU info: $line ---"
    done

    echo "--- Debug: Getting GPU PCI IDs for reattachment ---"
    local gpu_ids=$(lspci -nn | grep -i "VGA compatible controller" | awk '{print $1}')

    if [ -z "$gpu_ids" ]; then
        printf "ERROR: No GPU found.\\n"
        printf "%s: Error: No GPU found.\\n" "$function_name"
        echo "--- Debug: Exiting ${function_name} as no GPU IDs found ---"
        return 1
    fi

    printf "INFO: Found GPU(s) with PCI ID(s): $gpu_ids\\n"
    echo "--- Debug: Found GPU(s) with PCI ID(s): $gpu_ids ---"

    for id in $gpu_ids; do
        printf "INFO: Processing GPU with PCI ID: $id\\n"
        echo "--- Debug: Processing GPU ID for reattachment: $id ---"
        # Unbind from current driver (e.g., vfio-pci)
        if [ -e "/sys/bus/pci/devices/0000:$id/driver" ]; then
            printf "INFO: Unbinding GPU $id from current driver\\n"
            echo "--- Debug: Unbinding 0000:$id from current driver ---"
            echo "0000:$id" > /sys/bus/pci/devices/0000:$id/driver/unbind
            if [ $? -eq 0 ]; then
                printf "INFO: Successfully unbound GPU $id\\n"
                echo "--- Debug: Successfully unbound GPU $id ---"
            else
                printf "WARNING: Failed to unbind GPU $id\\n"
                echo "--- Debug: Failed to unbind GPU $id ---"
            fi
        else
            printf "INFO: GPU $id is not bound to any driver\\n"
            echo "--- Debug: GPU $id is not bound to any driver, skipping unbind ---"
        fi

        # Reset driver_override
        printf "INFO: Clearing driver_override for GPU $id\\n"
        echo "--- Debug: Clearing driver_override for 0000:$id ---"
        if ! echo > "/sys/bus/pci/devices/0000:$id/driver_override"; then
            printf "WARNING: Failed to clear driver_override for GPU $id. This might prevent binding to the desired driver.\\n"
            echo "--- Debug: WARNING - Failed to clear driver_override for 0000:$id ---"
        fi

        # Determine the correct driver (amdgpu or nouveau/nvidia)
        local vendor_id=$(lspci -n -s "$id" | awk \'{print $3}\' | cut -d\':\' -f1)
        local driver=""
        case "$vendor_id" in
            1002) # AMD
                driver="amdgpu"
                ;;
            10de) # NVIDIA
                driver="$preferred_nvidia_driver" # Use the determined preference
                echo "--- Debug: NVIDIA card detected. Using preferred driver: $driver ---"
                ;;
            *)
                printf "ERROR: Unknown GPU vendor: $vendor_id for PCI ID $id. Cannot determine driver.\\n"
                echo "--- Debug: ERROR - Unknown GPU vendor: $vendor_id for PCI ID $id ---"
                continue # Skip to the next GPU ID
                ;;
        esac

        printf "INFO: Setting driver_override to $driver for GPU $id\\n"
        echo "--- Debug: Setting driver_override to $driver for 0000:$id ---"
        if ! echo "$driver" > "/sys/bus/pci/devices/0000:$id/driver_override"; then
            printf "WARNING: Failed to set driver_override to $driver for GPU $id. Reattachment might be unreliable.\\n"
            echo "--- Debug: WARNING - Failed to set driver_override to $driver for 0000:$id ---"
        fi

        printf "INFO: Attempting to load $driver driver\\n"
        echo "--- Debug: Attempting to load $driver driver for $id ---"
        if ! modprobe "$driver"; then
            printf "ERROR: Failed to load $driver driver. You may need to install it.\\n"
            printf "%s: Error: Failed to load $driver driver. You may need to install it.\\n" "$function_name"
            echo "--- Debug: Failed to load $driver driver for $id. Skipping... ---"
            continue # Skip to the next GPU ID
        else
            printf "INFO: $driver driver loaded successfully.\\n"
            echo "--- Debug: $driver driver loaded successfully for $id ---"
        fi

        printf "INFO: Probing for new driver for GPU $id\\n"
        echo "--- Debug: Probing for new driver for GPU $id (0000:$id) ---"
        echo "0000:$id" > /sys/bus/pci/drivers_probe
        if [ $? -eq 0 ]; then
            printf "INFO: Successfully probed for new driver for GPU $id\\n"
            echo "--- Debug: Successfully probed for new driver for GPU $id ---"
        else
            printf "WARNING: Failed to probe for new driver for GPU $id\\n"
            echo "--- Debug: Failed to probe for new driver for GPU $id ---"
        fi

        # Explicitly bind the driver if it's not automatically bound
        if [ ! -e "/sys/bus/pci/devices/0000:$id/driver" ]; then
            printf "INFO: Attempting to explicitly bind $driver to GPU $id\\n"
            echo "--- Debug: Attempting to explicitly bind $driver to GPU $id (0000:$id) ---"
            
            local bind_message
            # Attempt to bind and capture any output (especially stderr from the shell for the redirection)
            bind_message=$(echo "0000:$id" > "/sys/bus/pci/drivers/$driver/bind" 2>&1)
            local bind_exit_code=$?

            if [ $bind_exit_code -eq 0 ]; then
                printf "INFO: Successfully bound $driver to GPU $id\\n"
                echo "--- Debug: Successfully bound $driver to GPU $id ---"
            else
                # Bind command failed. Check if it's because the device is now (or was already) bound to the target driver.
                local current_driver_link_target=""
                if [ -L "/sys/bus/pci/devices/0000:$id/driver" ]; then
                    current_driver_link_target=$(basename "$(readlink "/sys/bus/pci/devices/0000:$id/driver")")
                fi

                if [ "$current_driver_link_target" == "$driver" ]; then
                    # The bind command failed, but the device IS bound to the target driver.
                    # This is the "File exists" scenario (EEXIST). Treat as a warning.
                    printf "WARNING: Explicit bind command for $driver to GPU $id failed (exit code $bind_exit_code, message: '$bind_message'), but device is now correctly bound to $driver. Assuming success.\\n"
                    echo "--- Debug: Explicit bind for $driver to GPU $id failed (message: '$bind_message'), but it's now bound to $driver. Assuming OK. ---"
                else
                    # The bind command failed, AND the device is not bound to the target driver. This is a real error.
                    printf "ERROR: Failed to bind $driver to GPU $id. Exit code: $bind_exit_code. Message: '$bind_message'. Device driver is '$current_driver_link_target'.\\n"
                    printf "%s: Error: Failed to bind $driver to GPU $id. Details: $bind_message\\n" "$function_name"
                    echo "--- Debug: Failed to bind $driver to GPU $id. Error: '$bind_message'. Current driver: '$current_driver_link_target' ---"
                    # Original script continues with other GPUs, so we do the same.
                fi
            fi
        else
            # This block is executed if /sys/bus/pci/devices/0000:$id/driver symlink existed initially.
            local actual_bound_driver_name
            # Ensure readlink output is handled safely, especially if symlink is broken/unexpected
            if [ -L "/sys/bus/pci/devices/0000:$id/driver" ]; then
                actual_bound_driver_name=$(basename "$(readlink "/sys/bus/pci/devices/0000:$id/driver")")
            else
                actual_bound_driver_name="<unknown or no symlink>"
            fi
            
            echo "--- Debug: GPU $id (0000:$id) already has a driver link, points to: $actual_bound_driver_name ---"
            if [ "$actual_bound_driver_name" == "$driver" ]; then
                printf "INFO: GPU $id already bound to target driver $driver.\\n"
                echo "--- Debug: GPU $id already bound to $driver. No explicit bind needed. ---"
            else
                printf "WARNING: GPU $id is already linked to driver $actual_bound_driver_name, not the target $driver. This might be unexpected.\\n"
                echo "--- Debug: GPU $id linked to $actual_bound_driver_name, but script intended $driver. Check if this is an issue. ---"
            fi
        fi

        printf "INFO: Clearing driver_override for GPU $id post-binding attempt\\n"
        echo "--- Debug: Clearing driver_override for 0000:$id post-binding attempt ---"
        if ! echo > "/sys/bus/pci/devices/0000:$id/driver_override"; then
            printf "WARNING: Failed to clear driver_override for GPU $id post-binding attempt.\\n"
            echo "--- Debug: WARNING - Failed to clear driver_override for 0000:$id post-binding attempt ---"
        fi
    done

    printf "INFO: GPU driver and IOMMU group after reattachment:\\n"
    echo "--- Debug: GPU driver and IOMMU group (after reattachment) ---"
    lspci -nnk | grep -A3 "VGA compatible controller" | while read -r line; do
        printf "INFO: $line\\n"
        echo "--- Debug: Final GPU info: $line ---"
    done

    printf "INFO: GPU reattachment process completed.\\n"
    printf "%s: GPU reattachment process completed. Check logs for details.\\n" "$function_name"
    echo "--- Debug: Exiting ${function_name} ---"
}

# Checks the current status of the GPU
# gpu passthrough status
#
gpu-pts() {
    local function_name="${FUNCNAME[0]}"
    # Corrected flags:
    local is_any_gpu_on_vfio=false      # True if lspci -nnk shows a VGA/3D controller using vfio-pci
    local host_drivers_for_gpu=""     # Name(s) of host driver(s) if a VGA/3D controller is using one
    local vga_devices_processed=false # Flag to check if any VGA/3D device block was processed

    # Define colors using printf, similar to lo1 module
    local CYAN=$(printf '\\033[0;36m')
    local MAGENTA=$(printf '\\033[0;35m') # Magenta is often perceived as pinkish-red
    local YELLOW=$(printf '\\033[0;33m')
    local INDIGO_BLUE=$(printf '\\033[38;2;75;0;130m') # True color for Indigo Blue
    local RED=$(printf '\\033[0;31m')
    local NC=$(printf '\\033[0m') # No Color

    echo "--- GPU Passthrough Status ---"
    echo -e "=============================="

    # Store VFIO-PCI module status for later display (informational only)
    local vfio_pci_loaded_info=""
    if lsmod | grep -q "vfio_pci"; then
        vfio_pci_loaded_info="[INFO] ${CYAN}VFIO-PCI module is loaded.${NC}"
    else
        vfio_pci_loaded_info="[INFO] ${MAGENTA}VFIO-PCI module is NOT loaded.${NC}"
    fi

    echo -e "\\n--- Kernel Drivers for GPU(s) ---"
    # Process lspci -nnk output to determine drivers for VGA/3D controllers
    local temp_lspci_gpu_blocks="/tmp/gpu_pts_blocks.$$"
    # Grep for VGA/3D controllers and a few lines of context.
    # Using -A4 as a heuristic for context; can be adjusted if needed.
    lspci -nnk | grep -A4 -iE "VGA compatible controller|3D controller" > "$temp_lspci_gpu_blocks"
    
    if [ -s "$temp_lspci_gpu_blocks" ]; then
        local current_gpu_block_content=""
        # Read the grep output line by line
        while IFS= read -r line_from_grep; do
            # Check if the line is a VGA/3D controller line, indicating start of a new block
            if echo "$line_from_grep" | grep -qE "VGA compatible controller|3D controller"; then
                # Process previous block if it exists and was for a GPU
                if [ -n "$current_gpu_block_content" ] && echo "$current_gpu_block_content" | head -n1 | grep -qE "VGA compatible controller|3D controller"; then
                    echo "$current_gpu_block_content" # Print the full block for the user
                    vga_devices_processed=true
                    if echo "$current_gpu_block_content" | grep -q "Kernel driver in use: vfio-pci"; then
                        is_any_gpu_on_vfio=true
                    elif driver_line=$(echo "$current_gpu_block_content" | grep "Kernel driver in use:"); then
                        local driver_name=$(echo "$driver_line" | awk -F': ' '{print $2}')
                        if [ -n "$driver_name" ]; then
                            if [ -z "$host_drivers_for_gpu" ]; then host_drivers_for_gpu="$driver_name"; elif [[ ! "$host_drivers_for_gpu" =~ "$driver_name" ]]; then host_drivers_for_gpu="$host_drivers_for_gpu, $driver_name"; fi
                        fi
                    fi
                fi
                current_gpu_block_content="$line_from_grep" # Start new block
            elif [[ "$line_from_grep" == "--" ]]; then # grep -A separator, end of a block
                if [ -n "$current_gpu_block_content" ]; then
                    echo "$current_gpu_block_content" # Print the block
                    vga_devices_processed=true
                    if echo "$current_gpu_block_content" | grep -q "Kernel driver in use: vfio-pci"; then
                        is_any_gpu_on_vfio=true
                    elif driver_line=$(echo "$current_gpu_block_content" | grep "Kernel driver in use:"); then
                        local driver_name=$(echo "$driver_line" | awk -F': ' '{print $2}')
                        if [ -n "$driver_name" ]; then
                           if [ -z "$host_drivers_for_gpu" ]; then host_drivers_for_gpu="$driver_name"; elif [[ ! "$host_drivers_for_gpu" =~ "$driver_name" ]]; then host_drivers_for_gpu="$host_drivers_for_gpu, $driver_name"; fi
                        fi
                    fi
                    current_gpu_block_content="" # Reset block
                fi
                echo "$line_from_grep" # Print the "--" separator
            elif [ -n "$current_gpu_block_content" ]; then # Line is part of the current block
                current_gpu_block_content="$current_gpu_block_content"$'\\n'"$line_from_grep"
            fi
        done < "$temp_lspci_gpu_blocks"
        # Process the last accumulated block, if any
        if [ -n "$current_gpu_block_content" ]; then
            echo "$current_gpu_block_content"
            vga_devices_processed=true
            if echo "$current_gpu_block_content" | grep -q "Kernel driver in use: vfio-pci"; then
                is_any_gpu_on_vfio=true
            elif driver_line=$(echo "$current_gpu_block_content" | grep "Kernel driver in use:"); then
                local driver_name=$(echo "$driver_line" | awk -F': ' '{print $2}')
                if [ -n "$driver_name" ]; then
                    if [ -z "$host_drivers_for_gpu" ]; then host_drivers_for_gpu="$driver_name"; elif [[ ! "$host_drivers_for_gpu" =~ "$driver_name" ]]; then host_drivers_for_gpu="$host_drivers_for_gpu, $driver_name"; fi
                fi
            fi
        fi
    else
        echo -e "${YELLOW}No VGA compatible or 3D controllers found by primary lspci grep.${NC}"
    fi
    rm -f "$temp_lspci_gpu_blocks"

    # Fallback check if the above parsing didn't set flags but devices exist
    if ! $vga_devices_processed && lspci -nnk | grep -qE "VGA compatible controller|3D controller"; then
        vga_devices_processed=true # Mark that devices are present
        echo -e "${YELLOW}[INFO] Primary parsing of GPU drivers was inconclusive; performing fallback check.${NC}"
        # A simpler check on the full output if primary parsing failed to set flags
        local full_lspci_check_output=$(lspci -nnk)
        if echo "$full_lspci_check_output" | grep -A4 "VGA compatible controller" | grep -q "Kernel driver in use: vfio-pci"; then
            is_any_gpu_on_vfio=true
        fi
        # Check for host drivers only if not on vfio
        if ! $is_any_gpu_on_vfio; then
            # This could be more sophisticated to find all host drivers
            local found_host_driver_names=$(echo "$full_lspci_check_output" | grep -A4 "VGA compatible controller" | grep "Kernel driver in use:" | awk -F': ' '{print $2}' | sort -u | tr '\\n' ',' | sed 's/,$//')
            if [ -n "$found_host_driver_names" ] && [ "$found_host_driver_names" != "vfio-pci" ]; then # ensure it's not vfio-pci again
                 host_drivers_for_gpu="$found_host_driver_names"
            fi
        fi
    fi
    if ! $vga_devices_processed ; then
         echo -e "${YELLOW}No VGA compatible or 3D controllers were processed by this script.${NC}"
    fi

    echo -e "\\n--- IOMMU Groups (Filtered for GPU(s)) ---"
    if ! command -v find &>/dev/null || ! command -v ls &>/dev/null || ! command -v lspci &>/dev/null; then
        echo "Required commands (find, ls, lspci) not available to list IOMMU groups."
    else
        local gpu_pci_bus_ids=()
        # Get PCI bus IDs (e.g., 01:00.0) of VGA/3D controllers
        while IFS= read -r line; do
            gpu_pci_bus_ids+=("$(echo "$line" | awk '{print $1}')")
        done < <(lspci -nn | grep -iE "VGA compatible controller|3D controller")

        if [ ${#gpu_pci_bus_ids[@]} -eq 0 ]; then
            echo "No VGA/3D controllers found to filter IOMMU groups."
        else
            echo "Monitoring for GPU(s) at PCI Bus IDs: ${gpu_pci_bus_ids[*]}"
            local overall_iommu_groups_found=false
            local gpu_related_group_displayed=false

            for iommu_group_dir in $(find /sys/kernel/iommu_groups/ -mindepth 1 -maxdepth 1 -type d 2>/dev/null | sort -V); do
                overall_iommu_groups_found=true
                local group_id=$(basename "$iommu_group_dir")
                local devices_in_group_output=""
                local this_group_contains_gpu=false

                # Iterate over devices to build output and check for GPU presence
                for device_symlink_name in $(ls -1 "$iommu_group_dir"/devices/ 2>/dev/null | sort -V); do
                    # device_symlink_name is like 0000:01:00.0
                    local device_pci_bus_id_full="$device_symlink_name"
                    # Strip leading "0000:" to get short bus ID like "01:00.0"
                    local device_pci_bus_id_short="${device_symlink_name#0000:}" 
                    
                    local device_info
                    device_info=$(lspci -nns "$device_pci_bus_id_full" 2>/dev/null)
                    
                    if [ -n "$device_info" ]; then
                        devices_in_group_output+="\\t${device_info}\\n"
                        # Check if this device is one of the target GPUs
                        for gpu_id in "${gpu_pci_bus_ids[@]}"; do
                            if [[ "$device_pci_bus_id_short" == "$gpu_id" ]]; then
                                this_group_contains_gpu=true
                                break 
                            fi
                        done
                    else
                        devices_in_group_output+="\\tError reading device info for $device_pci_bus_id_full\\n"
                    fi
                done

                if $this_group_contains_gpu; then
                    echo -e "IOMMU Group ${group_id}:"
                    # Remove last newline character from devices_in_group_output before printing
                    echo -e "${devices_in_group_output%\\n}" 
                    gpu_related_group_displayed=true
                fi
            done

            if ! $overall_iommu_groups_found; then
                echo "No IOMMU groups found by 'find' command."
            elif ! $gpu_related_group_displayed; then
                echo "No IOMMU groups found containing the identified GPU(s): ${gpu_pci_bus_ids[*]}"
            fi
        fi
    fi

    echo -e "\\n--- Loaded Kernel Modules (GPU related) ---"
    if lsmod | grep -E "vfio|nvidia|nouveau|amdgpu|radeon" --color=never; then
        : # lsmod already printed
    else
        echo "No common GPU-related modules (vfio, nvidia, nouveau, amdgpu, radeon) loaded."
    fi

    echo -e "\\n--- Default Boot Setting (persisted by gpu-pt3) ---"
    local vfio_conf_file="/etc/modprobe.d/vfio.conf"
    local blacklist_conf_file="/etc/modprobe.d/blacklist.conf"
    local pt3_default_state_msg=""

    # Check for vfio.conf and vfio-pci ids
    if [ -f "$vfio_conf_file" ] && grep -q -E "^options vfio-pci ids=" "$vfio_conf_file"; then
        pt3_default_state_msg="${INDIGO_BLUE}Persistent passthrough (gpu-pt3): ENABLED${NC}\\n"
        pt3_default_state_msg+="${INDIGO_BLUE}  - GPUs are likely assigned to vfio-pci at boot via $vfio_conf_file.${NC}"
        
        # Check blacklist status
        if [ -f "$blacklist_conf_file" ] && (grep -q "blacklist radeon" "$blacklist_conf_file" || grep -q "blacklist amdgpu" "$blacklist_conf_file"); then
            pt3_default_state_msg+="\\n${INDIGO_BLUE}  - Native GPU drivers (radeon/amdgpu) are blacklisted in $blacklist_conf_file.${NC}"
        else
            pt3_default_state_msg+="\\n${INDIGO_BLUE}  - Native GPU driver blacklisting in $blacklist_conf_file is NOT DETECTED or file is missing.${NC}"
        fi
    else
        pt3_default_state_msg="${RED}Persistent passthrough (gpu-pt3): DISABLED or NOT CONFIGURED${NC}\\n"
        pt3_default_state_msg+="${RED}  - $vfio_conf_file is missing or does not assign GPUs to vfio-pci.${NC}"

        # Check blacklist status even if vfio.conf is not set for passthrough (could be an inconsistent state)
        if [ -f "$blacklist_conf_file" ] && (grep -q "blacklist radeon" "$blacklist_conf_file" || grep -q "blacklist amdgpu" "$blacklist_conf_file"); then
            pt3_default_state_msg+="\\n${RED}  - Note: Native GPU drivers might still be blacklisted in $blacklist_conf_file (check for inconsistency).${NC}"
        else
            pt3_default_state_msg+="\\n${RED}  - Native GPU driver blacklisting in $blacklist_conf_file also NOT DETECTED or file is missing.${NC}"
        fi
    fi
    echo -e "$pt3_default_state_msg"

    # Display the VFIO-PCI module status
    echo -e "\\n--- VFIO-PCI Module Status ---"
    echo -e "${vfio_pci_loaded_info}"

    # Now display the Overall GPU State Determination
    echo -e "\\n--- Overall GPU State Determination ---"
    if $is_any_gpu_on_vfio; then
        echo -e "${CYAN}Boolean DETACHED state: true (a GPU device is actively using vfio-pci).${NC}"
        echo -e "${CYAN}--- Summary: GPU appears to be DETACHED (for VM use) ---${NC}"
        echo -e "${CYAN}    - At least one GPU device (VGA/3D controller) is bound to vfio-pci.${NC}"
        if [ -n "$host_drivers_for_gpu" ]; then
             echo -e "${YELLOW}    - Note: Other GPU devices might be ATTACHED to host (driver(s): $host_drivers_for_gpu). State could be MIXED.${NC}"
        fi
    elif [ -n "$host_drivers_for_gpu" ]; then
        echo -e "${MAGENTA}Boolean DETACHED state: false (GPU is attached to host driver(s): $host_drivers_for_gpu).${NC}"
        echo -e "${MAGENTA}--- Summary: GPU appears to be ATTACHED to host (driver(s): $host_drivers_for_gpu) ---${NC}"
        echo -e "${MAGENTA}    - GPU device(s) (VGA/3D controller) are using host driver(s): $host_drivers_for_gpu.${NC}"
        echo -e "${MAGENTA}    - No VGA/3D controller found using vfio-pci.${NC}"
    else
        # No GPU on vfio, no GPU on host driver. Check if GPUs were found at all.
        if $vga_devices_processed || lspci -nnk | grep -qE "VGA compatible controller|3D controller"; then # Check if any VGA/3D controller was found
            echo -e "${YELLOW}Boolean DETACHED state: indeterminate (GPU found, but no driver identified as 'in use' by this script).${NC}"
            echo -e "${YELLOW}--- Summary: GPU state is UNCLEAR for VGA/3D controllers ---${NC}"
            echo -e "${YELLOW}    - A VGA/3D controller was detected, but it's not using 'vfio-pci' nor any other recognized host driver.${NC}"
            echo -e "${YELLOW}    - It might be unbound. Check 'Kernel Drivers for GPU(s)' section and IOMMU details.${NC}"
        else
            echo -e "${YELLOW}Boolean DETACHED state: N/A (No VGA/3D GPU controllers detected).${NC}"
            echo -e "${YELLOW}--- Summary: No VGA/3D GPU controllers detected by lspci -nnk ---${NC}"
        fi
        echo -e "${YELLOW}    - Review IOMMU groups and loaded modules above.${NC}"
    fi

    echo ""
    printf "%s: GPU status check completed.\\n" "$function_name"
    echo "---------------------------------"
}
